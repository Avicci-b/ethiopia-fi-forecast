{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a60f0bfc",
   "metadata": {},
   "source": [
    "# Task 1: Data Exploration and Enrichment\n",
    "## Ethiopia Financial Inclusion Forecasting\n",
    "\n",
    "**Objective:** Understand the starter dataset and enrich it with additional data for forecasting.\n",
    "\n",
    "### Tasks:\n",
    "1. Understand the Schema\n",
    "2. Explore the Data  \n",
    "3. Enrich the Dataset\n",
    "4. Follow the Schema\n",
    "5. Document Your Additions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff7c61d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported\n"
     ]
    }
   ],
   "source": [
    "# Setup and imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"‚úÖ Libraries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8edb3980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Data Loaded Successfully\n",
      "Main dataset: 43 rows, 34 columns\n",
      "Reference codes: 71 rows, 4 columns\n",
      "\n",
      "Main dataset columns: ['record_id', 'record_type', 'category', 'pillar', 'indicator', 'indicator_code', 'indicator_direction', 'value_numeric', 'value_text', 'value_type', 'unit', 'observation_date', 'period_start', 'period_end', 'fiscal_year', 'gender', 'location', 'region', 'source_name', 'source_type', 'source_url', 'confidence', 'related_indicator', 'relationship_type', 'impact_direction', 'impact_magnitude', 'impact_estimate', 'lag_months', 'evidence_basis', 'comparable_country', 'collected_by', 'collection_date', 'original_text', 'notes']\n"
     ]
    }
   ],
   "source": [
    "# Load the two CSV files\n",
    "main_df = pd.read_csv('../data/raw/ethiopia_fi_unified_data.csv')\n",
    "ref_df = pd.read_csv('../data/raw/reference_codes.csv')\n",
    "\n",
    "print(\"üìä Data Loaded Successfully\")\n",
    "print(f\"Main dataset: {main_df.shape[0]} rows, {main_df.shape[1]} columns\")\n",
    "print(f\"Reference codes: {ref_df.shape[0]} rows, {ref_df.shape[1]} columns\")\n",
    "print(\"\\nMain dataset columns:\", list(main_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59add26",
   "metadata": {},
   "source": [
    "# Task 1.1  Understand the Schema\n",
    "\n",
    "The unified schema uses `record_type` to differentiate:\n",
    "- `observation`: Measured values\n",
    "- `event`: Policies, product launches, milestones\n",
    "- `impact_link`: Relationships between events and indicators\n",
    "- `target`: Official policy goals\n",
    "\n",
    "**Key Design Principle:** Events are NOT pre-assigned to pillars. Their effects are captured through `impact_link` records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "851a0dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring recoed types...\n",
      "üìà RECORD TYPE DISTRIBUTION\n",
      "==================================================\n",
      "record_type\n",
      "observation    30\n",
      "event          10\n",
      "target          3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìã SAMPLE OF EACH RECORD TYPE\n",
      "==================================================\n",
      "\n",
      "--- OBSERVATION ---\n",
      "record_id              indicator  value_numeric observation_date category pillar\n",
      " REC_0001 Account Ownership Rate           22.0       2014-12-31      NaN ACCESS\n",
      " REC_0002 Account Ownership Rate           35.0       2017-12-31      NaN ACCESS\n",
      "\n",
      "--- TARGET ---\n",
      "record_id                   indicator  value_numeric observation_date category pillar\n",
      " REC_0031      Account Ownership Rate           70.0       2025-12-31      NaN ACCESS\n",
      " REC_0032 Fayda Digital ID Enrollment     90000000.0       2028-12-31      NaN ACCESS\n",
      "\n",
      "--- EVENT ---\n",
      "record_id                            indicator  value_numeric observation_date       category pillar\n",
      " EVT_0001                      Telebirr Launch            NaN       2021-05-17 product_launch    NaN\n",
      " EVT_0002 Safaricom Ethiopia Commercial Launch            NaN       2022-08-01   market_entry    NaN\n"
     ]
    }
   ],
   "source": [
    "print(\"Exploring recoed types...\")\n",
    "# Record type distribution\n",
    "print(\"üìà RECORD TYPE DISTRIBUTION\")\n",
    "print(\"=\" * 50)\n",
    "record_counts = main_df['record_type'].value_counts()\n",
    "print(record_counts)\n",
    "\n",
    "print(\"\\nüìã SAMPLE OF EACH RECORD TYPE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for rt in main_df['record_type'].unique():\n",
    "    print(f\"\\n--- {rt.upper()} ---\")\n",
    "    sample = main_df[main_df['record_type'] == rt].head(2)\n",
    "    # Select relevant columns for display\n",
    "    display_cols = [c for c in ['record_id', 'indicator', 'value_numeric', \n",
    "                               'observation_date', 'category', 'pillar'] \n",
    "                   if c in sample.columns]\n",
    "    print(sample[display_cols].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7baf3619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring record types...\n",
      "üî§ REFERENCE CODES EXPLORATION\n",
      "==================================================\n",
      "Unique fields: 13\n",
      "\n",
      "Field distribution:\n",
      "field\n",
      "value_type             11\n",
      "category               10\n",
      "source_type             8\n",
      "pillar                  7\n",
      "record_type             6\n",
      "confidence              4\n",
      "relationship_type       4\n",
      "impact_direction        4\n",
      "impact_magnitude        4\n",
      "evidence_basis          4\n",
      "indicator_direction     3\n",
      "gender                  3\n",
      "location                3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìù SAMPLES OF KEY FIELDS:\n",
      "\n",
      "record_type:\n",
      "  observation: Actual measured value from a source\n",
      "  event: Policy launch market event or milestone\n",
      "  impact_link: Relationship between event and indicator (links via parent_id)\n",
      "\n",
      "category:\n",
      "  product_launch: New product or service introduced\n",
      "  market_entry: New competitor enters market\n",
      "  market_exit: Competitor leaves market\n",
      "\n",
      "pillar:\n",
      "  ACCESS: Can people reach services? Coverage devices accounts\n",
      "  USAGE: Are people actively using? Transactions active users\n",
      "  QUALITY: Do services work? Success rates uptime\n"
     ]
    }
   ],
   "source": [
    "print(\"Exploring record types...\")\n",
    "# Explore reference codes\n",
    "print(\"üî§ REFERENCE CODES EXPLORATION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Unique fields: {ref_df['field'].nunique()}\")\n",
    "print(\"\\nField distribution:\")\n",
    "print(ref_df['field'].value_counts())\n",
    "\n",
    "# Show samples of important fields\n",
    "print(\"\\nüìù SAMPLES OF KEY FIELDS:\")\n",
    "for field in ['record_type', 'category', 'pillar', 'indicator_code']:\n",
    "    if field in ref_df['field'].values:\n",
    "        samples = ref_df[ref_df['field'] == field].head(3)\n",
    "        print(f\"\\n{field}:\")\n",
    "        for _, row in samples.iterrows():\n",
    "            print(f\"  {row['code']}: {row['description']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bf2d1f",
   "metadata": {},
   "source": [
    "## Task 1.2 Explore the Data\n",
    "\n",
    "I'll examine:\n",
    "- Count records by record_type, pillar, source_type, and confidence\n",
    "- Temporal range of observations\n",
    "- Unique indicators and their coverage\n",
    "- Cataloged events and their dates\n",
    "- Existing impact links and relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2d628a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting the records with values of..\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_type</th>\n",
       "      <th>pillar</th>\n",
       "      <th>source_type</th>\n",
       "      <th>confidence</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>observation</td>\n",
       "      <td>ACCESS</td>\n",
       "      <td>operator</td>\n",
       "      <td>high</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>observation</td>\n",
       "      <td>ACCESS</td>\n",
       "      <td>regulator</td>\n",
       "      <td>high</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>observation</td>\n",
       "      <td>ACCESS</td>\n",
       "      <td>research</td>\n",
       "      <td>high</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>observation</td>\n",
       "      <td>ACCESS</td>\n",
       "      <td>survey</td>\n",
       "      <td>high</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>observation</td>\n",
       "      <td>AFFORDABILITY</td>\n",
       "      <td>research</td>\n",
       "      <td>medium</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>observation</td>\n",
       "      <td>GENDER</td>\n",
       "      <td>regulator</td>\n",
       "      <td>high</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>observation</td>\n",
       "      <td>GENDER</td>\n",
       "      <td>research</td>\n",
       "      <td>high</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>observation</td>\n",
       "      <td>GENDER</td>\n",
       "      <td>survey</td>\n",
       "      <td>high</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>observation</td>\n",
       "      <td>GENDER</td>\n",
       "      <td>survey</td>\n",
       "      <td>medium</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>observation</td>\n",
       "      <td>USAGE</td>\n",
       "      <td>calculated</td>\n",
       "      <td>high</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>observation</td>\n",
       "      <td>USAGE</td>\n",
       "      <td>operator</td>\n",
       "      <td>high</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>target</td>\n",
       "      <td>ACCESS</td>\n",
       "      <td>policy</td>\n",
       "      <td>high</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>target</td>\n",
       "      <td>GENDER</td>\n",
       "      <td>policy</td>\n",
       "      <td>medium</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    record_type         pillar source_type confidence  count\n",
       "0   observation         ACCESS    operator       high      2\n",
       "1   observation         ACCESS   regulator       high      2\n",
       "2   observation         ACCESS    research       high      2\n",
       "3   observation         ACCESS      survey       high      8\n",
       "4   observation  AFFORDABILITY    research     medium      1\n",
       "5   observation         GENDER   regulator       high      1\n",
       "6   observation         GENDER    research       high      1\n",
       "7   observation         GENDER      survey       high      1\n",
       "8   observation         GENDER      survey     medium      1\n",
       "9   observation          USAGE  calculated       high      2\n",
       "10  observation          USAGE    operator       high      9\n",
       "11       target         ACCESS      policy       high      2\n",
       "12       target         GENDER      policy     medium      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Counting the records with values of..\")\n",
    "record_counts = (\n",
    "    main_df.groupby([\"record_type\", \"pillar\", \"source_type\", \"confidence\"])\n",
    "      .size()  # counts rows in each group\n",
    "      .reset_index(name=\"count\")  # turn into DataFrame with a 'count' column\n",
    ")\n",
    "\n",
    "# Display the result\n",
    "record_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c127f10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal analysis...\n",
      "üìÖ TEMPORAL ANALYSIS\n",
      "==================================================\n",
      "Date-related columns: ['observation_date', 'fiscal_year', 'collection_date']\n",
      "\n",
      "Date Range: 2014-12-31 00:00:00 to 2030-12-31 00:00:00\n",
      "\n",
      "Records by year:\n",
      "year\n",
      "2014     1\n",
      "2017     1\n",
      "2021     7\n",
      "2022     1\n",
      "2023     2\n",
      "2024    14\n",
      "2025    15\n",
      "2028     1\n",
      "2030     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Observations by year:\n",
      "year\n",
      "2014     1\n",
      "2017     1\n",
      "2021     5\n",
      "2023     1\n",
      "2024    11\n",
      "2025    11\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Temporal analysis...\")\n",
    "# Temporal analysis\n",
    "print(\"üìÖ TEMPORAL ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check date columns\n",
    "date_cols = [col for col in main_df.columns if 'date' in col.lower() or 'year' in col.lower()]\n",
    "print(f\"Date-related columns: {date_cols}\")\n",
    "\n",
    "if 'observation_date' in main_df.columns:\n",
    "    # Parse dates\n",
    "    main_df['observation_date_parsed'] = pd.to_datetime(main_df['observation_date'], errors='coerce')\n",
    "    \n",
    "    # Get date range\n",
    "    valid_dates = main_df['observation_date_parsed'].dropna()\n",
    "    if not valid_dates.empty:\n",
    "        print(f\"\\nDate Range: {valid_dates.min()} to {valid_dates.max()}\")\n",
    "        \n",
    "        # Count by year\n",
    "        main_df['year'] = main_df['observation_date_parsed'].dt.year\n",
    "        year_counts = main_df['year'].value_counts().sort_index()\n",
    "        print(\"\\nRecords by year:\")\n",
    "        print(year_counts)\n",
    "        \n",
    "        # Observations by year\n",
    "        obs_by_year = main_df[main_df['record_type'] == 'observation'].groupby('year').size()\n",
    "        print(\"\\nObservations by year:\")\n",
    "        print(obs_by_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc3203d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing all unique indicators...\n",
      "üìä INDICATORS AND PILLARS\n",
      "==================================================\n",
      "Total observations: 30\n",
      "\n",
      "Observations by pillar:\n",
      "pillar\n",
      "ACCESS           14\n",
      "USAGE            11\n",
      "GENDER            4\n",
      "AFFORDABILITY     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique indicators: 19\n",
      "\n",
      "Top 10 indicators:\n",
      "indicator_code\n",
      "ACC_OWNERSHIP      6\n",
      "ACC_FAYDA          3\n",
      "ACC_4G_COV         2\n",
      "USG_P2P_COUNT      2\n",
      "GEN_GAP_ACC        2\n",
      "ACC_MM_ACCOUNT     2\n",
      "USG_MPESA_USERS    1\n",
      "GEN_MM_SHARE       1\n",
      "AFF_DATA_INCOME    1\n",
      "USG_ACTIVE_RATE    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Listing all unique indicators...\")\n",
    "# Indicators and pillars analysis\n",
    "print(\"üìä INDICATORS AND PILLARS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# For observations\n",
    "obs_df = main_df[main_df['record_type'] == 'observation']\n",
    "print(f\"Total observations: {obs_df.shape[0]}\")\n",
    "\n",
    "# Pillar distribution\n",
    "if 'pillar' in obs_df.columns:\n",
    "    print(\"\\nObservations by pillar:\")\n",
    "    print(obs_df['pillar'].value_counts())\n",
    "\n",
    "# Indicator coverage\n",
    "if 'indicator_code' in obs_df.columns:\n",
    "    print(f\"\\nUnique indicators: {obs_df['indicator_code'].nunique()}\")\n",
    "    print(\"\\nTop 10 indicators:\")\n",
    "    print(obs_df['indicator_code'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bcc466c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undestanding events that are catalogued and their data...\n",
      "üéØ EVENTS ANALYSIS\n",
      "==================================================\n",
      "Total events: 10\n",
      "\n",
      "Events by category:\n",
      "category\n",
      "product_launch    2\n",
      "infrastructure    2\n",
      "policy            2\n",
      "market_entry      1\n",
      "milestone         1\n",
      "partnership       1\n",
      "pricing           1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Event timeline:\n",
      "observation_date                              indicator       category\n",
      "      2021-05-17                        Telebirr Launch product_launch\n",
      "      2021-09-01                NFIS-II Strategy Launch         policy\n",
      "      2022-08-01   Safaricom Ethiopia Commercial Launch   market_entry\n",
      "      2023-08-01                 M-Pesa Ethiopia Launch product_launch\n",
      "      2024-01-01       Fayda Digital ID Program Rollout infrastructure\n",
      "      2024-07-29        Foreign Exchange Liberalization         policy\n",
      "      2024-10-01    P2P Transaction Count Surpasses ATM      milestone\n",
      "      2025-10-27           M-Pesa EthSwitch Integration    partnership\n",
      "      2025-12-15      Safaricom Ethiopia Price Increase        pricing\n",
      "      2025-12-18 EthioPay Instant Payment System Launch infrastructure\n"
     ]
    }
   ],
   "source": [
    "print(\"Undestanding events that are catalogued and their data...\")\n",
    "# Events analysis\n",
    "print(\"üéØ EVENTS ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "events_df = main_df[main_df['record_type'] == 'event']\n",
    "print(f\"Total events: {events_df.shape[0]}\")\n",
    "\n",
    "if 'category' in events_df.columns:\n",
    "    print(\"\\nEvents by category:\")\n",
    "    print(events_df['category'].value_counts())\n",
    "\n",
    "# Show event timeline\n",
    "if 'observation_date' in events_df.columns:\n",
    "    print(\"\\nEvent timeline:\")\n",
    "    event_timeline = events_df[['observation_date', 'indicator', 'category']].sort_values('observation_date')\n",
    "    print(event_timeline.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e96f33d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviewing the existing impact_links...\n",
      "üîó IMPACT LINKS ANALYSIS\n",
      "==================================================\n",
      "Total impact links: 0\n",
      "\n",
      "Impact links by pillar:\n",
      "Series([], Name: count, dtype: int64)\n",
      "\n",
      "Impact directions:\n",
      "Series([], Name: count, dtype: int64)\n",
      "\n",
      "Impact magnitudes:\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "print(\"Reviewing the existing impact_links...\")\n",
    "# Impact links analysis\n",
    "print(\"üîó IMPACT LINKS ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "impact_df = main_df[main_df['record_type'] == 'impact_link']\n",
    "print(f\"Total impact links: {impact_df.shape[0]}\")\n",
    "\n",
    "if 'pillar' in impact_df.columns:\n",
    "    print(\"\\nImpact links by pillar:\")\n",
    "    print(impact_df['pillar'].value_counts())\n",
    "\n",
    "# Show relationships\n",
    "if 'impact_direction' in impact_df.columns:\n",
    "    print(\"\\nImpact directions:\")\n",
    "    print(impact_df['impact_direction'].value_counts())\n",
    "\n",
    "if 'impact_magnitude' in impact_df.columns:\n",
    "    print(\"\\nImpact magnitudes:\")\n",
    "    print(impact_df['impact_magnitude'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e3fe50",
   "metadata": {},
   "source": [
    "## Data Quality Assessment\n",
    "\n",
    "### Issues Identified:\n",
    "1. **Sparse temporal data**: Only 5 data points for ACCESS pillar (2011, 2014, 2017, 2021, 2024)\n",
    "2. **Missing years**: Gaps between survey years need interpolation\n",
    "3. **Mixed data types**: Some numeric values may be stored as text\n",
    "4. **Event-impact relationships**: Need validation against actual outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d09e3915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç DATA QUALITY CHECKS\n",
      "==================================================\n",
      "Missing values by column:\n",
      "related_indicator      100.00\n",
      "region                 100.00\n",
      "evidence_basis         100.00\n",
      "lag_months             100.00\n",
      "impact_estimate        100.00\n",
      "impact_magnitude       100.00\n",
      "impact_direction       100.00\n",
      "relationship_type      100.00\n",
      "notes                  100.00\n",
      "period_end              76.74\n",
      "period_start            76.74\n",
      "value_text              76.74\n",
      "collection_date         76.74\n",
      "category                76.74\n",
      "source_url              27.91\n",
      "pillar                  23.26\n",
      "unit                    23.26\n",
      "value_numeric           23.26\n",
      "indicator_direction     23.26\n",
      "original_text           23.26\n",
      "dtype: float64\n",
      "\n",
      "Data types:\n",
      "record_id                          object\n",
      "record_type                        object\n",
      "category                           object\n",
      "pillar                             object\n",
      "indicator                          object\n",
      "indicator_code                     object\n",
      "indicator_direction                object\n",
      "value_numeric                     float64\n",
      "value_text                         object\n",
      "value_type                         object\n",
      "unit                               object\n",
      "observation_date                   object\n",
      "period_start                       object\n",
      "period_end                         object\n",
      "fiscal_year                        object\n",
      "gender                             object\n",
      "location                           object\n",
      "region                            float64\n",
      "source_name                        object\n",
      "source_type                        object\n",
      "source_url                         object\n",
      "confidence                         object\n",
      "related_indicator                 float64\n",
      "relationship_type                 float64\n",
      "impact_direction                  float64\n",
      "impact_magnitude                  float64\n",
      "impact_estimate                   float64\n",
      "lag_months                        float64\n",
      "evidence_basis                    float64\n",
      "comparable_country                 object\n",
      "collected_by                       object\n",
      "collection_date                    object\n",
      "original_text                      object\n",
      "notes                             float64\n",
      "observation_date_parsed    datetime64[ns]\n",
      "year                                int32\n",
      "dtype: object\n",
      "\n",
      "Duplicate records: 0\n",
      "\n",
      "Value numeric summary:\n",
      "count    3.300000e+01\n",
      "mean     9.437258e+10\n",
      "std      4.231061e+11\n",
      "min      1.080000e+00\n",
      "25%      2.400000e+01\n",
      "50%      6.140000e+01\n",
      "75%      1.500000e+07\n",
      "max      2.380000e+12\n",
      "Name: value_numeric, dtype: float64\n",
      "\n",
      "Confidence level distribution:\n",
      "confidence\n",
      "high      40\n",
      "medium     3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data quality checks\n",
    "print(\"üîç DATA QUALITY CHECKS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Check for missing values\n",
    "print(\"Missing values by column:\")\n",
    "missing_pct = (main_df.isnull().sum() / len(main_df) * 100).round(2)\n",
    "print(missing_pct[missing_pct > 0].sort_values(ascending=False))\n",
    "\n",
    "# 2. Check data types\n",
    "print(\"\\nData types:\")\n",
    "print(main_df.dtypes)\n",
    "\n",
    "# 3. Check for duplicates\n",
    "print(f\"\\nDuplicate records: {main_df.duplicated().sum()}\")\n",
    "\n",
    "# 4. Check value consistency\n",
    "if 'value_numeric' in main_df.columns:\n",
    "    print(\"\\nValue numeric summary:\")\n",
    "    print(main_df['value_numeric'].describe())\n",
    "    \n",
    "# 5. Check confidence levels\n",
    "if 'confidence' in main_df.columns:\n",
    "    print(\"\\nConfidence level distribution:\")\n",
    "    print(main_df['confidence'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b66c51",
   "metadata": {},
   "source": [
    "## 3. Enrich the Dataset\n",
    "\n",
    "### Data Sources Needed:\n",
    "From the Additional Data Points Guide:\n",
    "\n",
    "#### A. Alternative Baselines:\n",
    "- IMF FAS, G20 indicators, GSMA, ITU, NBE reports\n",
    "\n",
    "#### B. Direct Correlation Indicators:\n",
    "- Active accounts, agent density, POS terminals, transaction volumes\n",
    "\n",
    "#### C. Indirect Correlation (Proxies):\n",
    "- Smartphone penetration, data affordability, urbanization, digital ID\n",
    "\n",
    "#### D. Market Nuances (Ethiopia-specific):\n",
    "- P2P dominance, mobile money-only users rare, low credit penetration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36f1b998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù ENRICHMENT PLAN\n",
      "==================================================\n",
      "\n",
      "Additional Observations:\n",
      "  ‚Ä¢ Quarterly mobile money users (2021-2024)\n",
      "  ‚Ä¢ Monthly agent network growth\n",
      "  ‚Ä¢ Smartphone penetration (annual)\n",
      "  ‚Ä¢ 4G coverage expansion\n",
      "  ‚Ä¢ Digital ID (Fayda) registration\n",
      "\n",
      "Additional Events:\n",
      "  ‚Ä¢ Specific regulatory changes (2022-2024)\n",
      "  ‚Ä¢ Bank-Mobile money partnerships\n",
      "  ‚Ä¢ Pricing changes for services\n",
      "  ‚Ä¢ Infrastructure milestones\n",
      "  ‚Ä¢ Regional expansion events\n",
      "\n",
      "Additional Impact Links:\n",
      "  ‚Ä¢ Validate Telebirr impact estimates\n",
      "  ‚Ä¢ Add M-Pesa market entry impacts\n",
      "  ‚Ä¢ Model infrastructure effects\n",
      "  ‚Ä¢ Include economic factors (inflation, FX)\n"
     ]
    }
   ],
   "source": [
    "# Create enrichment plan\n",
    "enrichment_plan = {\n",
    "    'additional_observations': [\n",
    "        'Quarterly mobile money users (2021-2024)',\n",
    "        'Monthly agent network growth',\n",
    "        'Smartphone penetration (annual)',\n",
    "        '4G coverage expansion',\n",
    "        'Digital ID (Fayda) registration'\n",
    "    ],\n",
    "    'additional_events': [\n",
    "        'Specific regulatory changes (2022-2024)',\n",
    "        'Bank-Mobile money partnerships',\n",
    "        'Pricing changes for services',\n",
    "        'Infrastructure milestones',\n",
    "        'Regional expansion events'\n",
    "    ],\n",
    "    'additional_impact_links': [\n",
    "        'Validate Telebirr impact estimates',\n",
    "        'Add M-Pesa market entry impacts',\n",
    "        'Model infrastructure effects',\n",
    "        'Include economic factors (inflation, FX)'\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"üìù ENRICHMENT PLAN\")\n",
    "print(\"=\" * 50)\n",
    "for category, items in enrichment_plan.items():\n",
    "    print(f\"\\n{category.replace('_', ' ').title()}:\")\n",
    "    for item in items:\n",
    "        print(f\"  ‚Ä¢ {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00d40db",
   "metadata": {},
   "source": [
    "## 4. Document Additions\n",
    "\n",
    "We'll create a `data_enrichment_log.md` file to track all additions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df6e5284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created data_enrichment_log.md template\n"
     ]
    }
   ],
   "source": [
    "# Create data enrichment log template\n",
    "log_content = \"\"\"# Data Enrichment Log\n",
    "\n",
    "## New Records Added\n",
    "\n",
    "### Observations Added:\n",
    "| record_id | pillar | indicator | indicator_code | value_numeric | observation_date | source_name | source_url | confidence | collected_by | collection_date | notes |\n",
    "|-----------|--------|-----------|----------------|---------------|------------------|-------------|------------|------------|--------------|-----------------|-------|\n",
    "\n",
    "### Events Added:\n",
    "| record_id | category | indicator | observation_date | source_name | source_url | confidence | collected_by | collection_date | notes |\n",
    "|-----------|----------|-----------|------------------|-------------|------------|------------|--------------|-----------------|-------|\n",
    "\n",
    "### Impact Links Added:\n",
    "| record_id | parent_id | pillar | related_indicator | impact_direction | impact_magnitude | lag_months | evidence_basis | confidence | collected_by | collection_date | notes |\n",
    "|-----------|-----------|--------|-------------------|------------------|------------------|------------|----------------|------------|--------------|-----------------|-------|\n",
    "\n",
    "## Summary of Additions\n",
    "- Total new observations: \n",
    "- Total new events: \n",
    "- Total new impact links: \n",
    "\n",
    "## Data Sources Used\n",
    "1. \n",
    "2. \n",
    "3. \n",
    "\n",
    "## Challenges and Limitations\n",
    "1. \n",
    "2. \n",
    "3. \n",
    "\"\"\"\n",
    "\n",
    "# Save to file\n",
    "with open('../data_enrichment_log.md', 'w') as f:\n",
    "    f.write(log_content)\n",
    "\n",
    "print(\"‚úÖ Created data_enrichment_log.md template\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "548e7cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Enrichment function ready - add actual data to use it\n"
     ]
    }
   ],
   "source": [
    "# Function to save enriched dataset (to be filled with actual data)\n",
    "def save_enriched_dataset(original_df, new_records, output_path):\n",
    "    \"\"\"\n",
    "    Combine original data with new records and save.\n",
    "    \n",
    "    Parameters:\n",
    "    original_df: Original DataFrame\n",
    "    new_records: List of new records (DataFrames or dicts)\n",
    "    output_path: Path to save enriched dataset\n",
    "    \"\"\"\n",
    "    # Convert new records to DataFrame\n",
    "    new_df = pd.DataFrame(new_records)\n",
    "    \n",
    "    # Combine with original\n",
    "    enriched_df = pd.concat([original_df, new_df], ignore_index=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    enriched_df.to_csv(output_path, index=False)\n",
    "    print(f\"‚úÖ Enriched dataset saved to {output_path}\")\n",
    "    print(f\"   Original: {len(original_df)} records\")\n",
    "    print(f\"   Added: {len(new_df)} records\")\n",
    "    print(f\"   Total: {len(enriched_df)} records\")\n",
    "    \n",
    "    return enriched_df\n",
    "\n",
    "# Example usage (commented out until we have actual data)\n",
    "\"\"\"\n",
    "# When you have actual new records:\n",
    "new_observations = [...]  # List of observation dicts\n",
    "new_events = [...]  # List of event dicts  \n",
    "new_impacts = [...]  # List of impact link dicts\n",
    "\n",
    "all_new_records = new_observations + new_events + new_impacts\n",
    "enriched_df = save_enriched_dataset(main_df, all_new_records, '../data/raw/ethiopia_fi_unriched_enriched.csv')\n",
    "\"\"\"\n",
    "print(\"üìÅ Enrichment function ready - add actual data to use it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cc4cac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà TASK 1 SUMMARY\n",
      "==================================================\n",
      "\n",
      "Main Dataset: 43 rows √ó 36 columns\n",
      "Reference Codes: 71 rows √ó 4 columns\n",
      "\n",
      "üìä Record Type Distribution:\n",
      "record_type\n",
      "observation    30\n",
      "event          10\n",
      "target          3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìÖ Temporal Coverage:\n",
      "Years with data: [2014, 2017, 2021, 2022, 2023, 2024, 2025, 2028, 2030]\n",
      "\n",
      "üîç Data Quality:\n",
      "Missing values: 614 total\n",
      "Duplicate rows: 0\n",
      "\n",
      "‚úÖ Task 1 Exploration Complete!\n",
      "\n",
      "Next: Add actual enrichment data to the dataset.\n"
     ]
    }
   ],
   "source": [
    "# Final summary statistics\n",
    "print(\"üìà TASK 1 SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\nMain Dataset: {main_df.shape[0]} rows √ó {main_df.shape[1]} columns\")\n",
    "print(f\"Reference Codes: {ref_df.shape[0]} rows √ó {ref_df.shape[1]} columns\")\n",
    "\n",
    "print(\"\\nüìä Record Type Distribution:\")\n",
    "print(main_df['record_type'].value_counts())\n",
    "\n",
    "print(\"\\nüìÖ Temporal Coverage:\")\n",
    "if 'year' in main_df.columns:\n",
    "    print(f\"Years with data: {sorted(main_df['year'].dropna().unique())}\")\n",
    "\n",
    "print(\"\\nüîç Data Quality:\")\n",
    "print(f\"Missing values: {main_df.isnull().sum().sum()} total\")\n",
    "print(f\"Duplicate rows: {main_df.duplicated().sum()}\")\n",
    "\n",
    "print(\"\\n‚úÖ Task 1 Exploration Complete!\")\n",
    "print(\"\\nNext: Add actual enrichment data to the dataset.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
